## N-gram 언어모델의 문제점

- N-gram 언어모델은 다음과 같은 문제점을 갖고 있습니다.
- 단어의 조합에 대한 경우의 수가 엄청나게 많기 때문에 아무리 많은 데이터를 수집하더라도 **특정 단어 조합의 경우 데이터셋에 한번도 존재하지않아서 계산식의 분모나 분자가 0**이 될 수 있습니다.

<img width="342" alt="스크린샷 2024-12-08 오후 7 20 22" src="https://github.com/user-attachments/assets/a567f14b-0a07-404a-a1cf-9457462762f8">

- 이런 문제를 해결하기 위해 최근에는 **딥러닝에 기반한 언어모델**이 주로 사용되고 있습니다.
- 이번 시간에는 딥러닝 모델중 하나인 RNN에 기반한 <b>글자(Character) 단위 언어모델링 방법인 Char-RNN 기법</b>을 실습해봅시다.

## 순환 신경망(RNN)

- CNN이 컴퓨터 비전Computer Vision 문제에 주로 사용되는 인공신경망 구조라면 이번 장에서 배울 <b>순환신경망(Recurrent Neural Networks(RNN))</b>은 <b>자연어 처리(Natural Language Processing(NLP))</b> 문제에 주로 사용되는 인공신경망 구조입니다.
- 좀 더 정확히 말하면, RNN은 시계열 데이터를 다루기에 최적화된 인공신경망입니다.
- **시계열 데이터**란 시간축을 중심으로 현재 시간의 데이터가 앞, 뒤 시간의 데이터와 연관 관계를 가지고 있는 데이터를 의미합니다. 예를 들어, 오늘의 주식 가격은 어제의 주식 가격과 연관이 있고, 내일의 주식 가격은 오늘의 주식 가격과 연관이 있습니다. 따라서 주식 가격은 시계열 데이터로 볼 수 있습니다.
- 주식 가격 이외에도 파형으로 표현되는 음성 데이터, 앞뒤 문맥을 가진 단어들의 집합으로 표현되는 자연어 데이터 등이 대표적인 시계열 데이터입니다.
- 이제 RNN 구조를 구체적으로 살펴봅시다. 아래 그림은 RNN의 구조를 나타냅니다.
- RNN은 기본적인 ANN 구조에서 이전 시간(t-1)의 은닉층의 출력값을 다음 시간(t)에 은닉층의 입력값으로 다시 집어넣는 경로가 추가된 형태입니다. 이 구조는 <b>“recurrent(순환되는)”</b>라는 단어에서 알 수 있듯이, 현재 시간 t의 결과가 다음 시간 t+1에 영향을 미치고, 이는 다시 다음 시간 t+2에 영향을 미치는 과정이 끊임없이 반복되는 인공신경망 구조입니다.

<img width="553" alt="스크린샷 2024-12-08 오후 7 26 14" src="https://github.com/user-attachments/assets/380d7fe5-6e2a-4009-ab39-d3c6e6bea246">

<img width="1135" alt="스크린샷 2024-12-08 오후 7 29 37" src="https://github.com/user-attachments/assets/477cf936-9acd-4a50-83df-9c2a7a7b7dbd">

<img width="1143" alt="스크린샷 2024-12-08 오후 7 29 53" src="https://github.com/user-attachments/assets/240b0985-b7b6-48d4-958a-442ef1395391">

- RNN을 다른 관점으로 바라보면, 시간축에 따라 인공신경망을 펼친Unfold 형태로 생각할 수 도 있습니다.
- 예를 들어, 5개의 단어로 이루어진 문장을 RNN의 인풋으로 사용한다면, 순환 연결이 없는 인공신경망을 5층으로 쌓은 것으로 바라볼 수 있습니다.
- 아래 그림은 unfold 형태의 RNN을 나타냅니다.

<img width="796" alt="스크린샷 2024-12-08 오후 7 43 55" src="https://github.com/user-attachments/assets/421f7468-34d4-42f7-9f68-019102d25920">
