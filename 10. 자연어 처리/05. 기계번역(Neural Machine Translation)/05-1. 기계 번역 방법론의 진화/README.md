## 기계 번역(Machine Translation) 방법론의 변화
- <b>기계번역(Machine Translation)</b> 방법론은 다음과 같은 변화를 거쳤습니다.
- <b>규칙 기반 기계번역(RBMT)</b> : 규칙 기반 기계번역은 번역에 대한 규칙을 하나하나 지정해서 번역하는 기법입니다. 규칙의 예외가 발생할 경우 성능이 떨어지고 새로운 언어를 추가할 때마다 새로운 규칙을 만들어 주어야만 한다는 문제점이 있습니다.
- <b>통계기반 기계번역(SMT)</b> : 통계기반 기계번역은 언어 쌍에 대한 통계적 특징을 추출하고 이를 이를 이용해서 기계번역을 수행하는 기법입니다. 규칙 기반 기계번역보다는 좋은 성능을 보여주지만 역시 일반화(generalization) 성능이 떨어지는 문제점이 있습니다.
- 신경망 기계번역(NMT) : 신경망 기계번역은 딥러닝을 이용해서 기계번역을 수행하는 기법입니다. 대량의 데이터를 이용해서 예외 상황에 대한 안정적인 처리가 가능하고 높은 성능을 보여줍니다. 최근 대부분의 회사에서 기계번역을 위해 채택하고 있는 방법론입니다.

![스크린샷 2024-12-10 오후 8 54 59](https://github.com/user-attachments/assets/b4c2ef93-687b-410e-89d4-b651e71efa18)

## seq2seq(Sequence-to-sequence) 모델

- <b>기계번역(NMT)</b>을 구현하기 위한 seq2seq(Sequence-to-sequence) 모델의 개념을 먼저 살펴봅시다.
- seq2seq 모델은 번역할 언어로 작성된 <b>소스 문장들(source sentences)</b>을 <b>인코더(Encoder)</b>를 이용해서 “생각” 벡터(“thought” vector) 형태로 변환하고, 이 “생각” 벡터를 특징값으로 이용해서 <b>디코더(Decoder)가 번역할 언어로 작성된 타겟 문장(target sentences)</b>을 생성하는 기법입니다.
- 아래 그림은 seq2seq를 이용해서 영어 문장을 프랑스어 문장으로 번역하는 법을 보여줍니다.

![스크린샷 2024-12-10 오후 8 56 17](https://github.com/user-attachments/assets/a0ce8035-64ba-4a7d-b409-38c18d058edf)


- seq2seq 모델은 다양한 구조를 이용해서 구현할 수 있지만 **RNN을 이용해서 구현하는 것**이 가장 일반적입니다. RNN을 이용해서 seq2seq 모델을 구현할 경우 다음의 과정을 거칩니다.
    - 번역할 언어로 작성된 소스 문장을 단어 단위로 쪼개고, 소스 문장의 단어들을 RNN의 인풋으로 넣는다. 
    - **소스 문장의 가장 마지막 단어를 인풋으로 넣고 구한 RNN의 상태값**을 **타겟 문장의 첫번째 단어의 예측을 시작할때 초기 상태값으로 지정**한다.
    - \<s\>는 문장의 시작을 의미하는 특수 키워드로써, 번역할 언어로 작성된 타겟 문장의 첫번째 단어로 사용한다.
    - \<s\>를 넣고 RNN이 다음에 올 수 있는 타겟 단어 후보군(Vocabulary)를 Softmax 행렬 형태(|V|)로 예측하면, 다음에 올 가장 그럴듯한 단어(Softmax 행렬 출력값 중 가장 큰값을 가지는 단어)를 선택해서 \<s\> <b>다음 단어(예를 들어, Je)로 확정</b>한다.
    - <b>\<s\>를 넣고 예측해서 구한 다음 단어(Je)를 RNN의 인풋으로 넣고</b>, 다시 다음에 올 수 있는 타겟 단어 후보군(Vocabulary)를 Softmax 행렬 형태(|V|)로 예측하면, 다음에 올 가장 그럴듯한 단어를 선택해서 <b>다음 단어(예를 들어, suis)로 확정</b>한다.
    - 위 과정을 <b>문장의 끝을 의미하는 특수 키워드 \</s\>가 다음 단어로 확정될 때까지 반복</b>한다.
    - <b>타겟 문장의 초기 상태값으로 소스 문장의 마지막 상태값을 사용하는 것</b>을 제외하면 앞서 배운 <b>Char-RNN과 비슷한 형태</b>임을 알 수 있습니다.
    - 아래 그림은 RNN을 이용한 seq2seq 모델 구조의 예시를 나타냅니다.