# 대규모 언어 모델로 텍스트 생성하기

## 키워드 정리

- **EXAONE**은 LG AI 연구원에서 만든 트랜스포머 디코더 기반의 대규모 언어 모델입니다. 3.5버전은 한국어와 영어를 잘 이해하며 비교적 적은 모델 파라미터를 가진 모델 중에서 경쟁력이 있습니다. 최신 LLM에서 채택하는 여러 기술을 사용하고 있습니다. 그룹 쿼리 어텐션, 실루 활성화 함수, RMS 정규화, 로터리 위치 임베딩 등입니다. 
- **토큰 디코딩**은 대규모 언어 모델이 출력한 로짓을 바탕으로 다음 토큰을 선택하는 과정입니다. 가장 기본적인 방법은 로짓을 소프트맥스 함수에 통과시켜 확률로 바꾼 후 이 확률을 기반으로 다음 토큰을 선택합니다. 온도 파라미터를 높이면 비교적 낮은 확률의 토큰이 선택될 가능성을 높일 수 있습니다. 최상위 로짓의 일부 토큰을 선택하는 `top-k` 방식과 누적 확률의 임곗값으로 토큰을 선택하는 `top-p` 방식이 널리 사용됩니다.
- **GPT**는 오픈 AI에서 개발된 트랜스포머 디코더 기반의 대규모 언어 모델입니다. `GPT-2`는 공개 되어 있지만 `GPT-3` 부터는 클로즈드 소스 정책을 유지하고 있습니다. `GPT-3.5`를 기반으로 하는 `ChatGPT`는 인공지능 분야에 큰 영향을 미쳤습니다. 최신 `GPT-4o` 모델은 다양한 작업에서 뛰어난 성능을 내는 모델 중 하나입니다. `ChatGPT` 웹 인터페이스 또는 파이썬 같은 프로그래밍 언어를 위해 제공되는 API를 통해 이런 모델을 사용할 수 있습니다. 

### transformers

- **AutoTokenizer**는 허깅페이스에서 제공하는 사전 훈련된 LLM 모델의 토크나이저를 직접 로드하기 위한 클래스입니다. `from_pretrained()` 클래스 메서드에 허깅페이스 모델 경로를 전달하여 불러올 수 있습니다. 비슷하게 트랜스포머 디코더 기반의 LLM 모델을 불러오려면 `AutoModelForCausalLM` 클래스를 사용합니다. 
- 파이프라인 객체를 호출할 때 다음과 같은 매개변수를 사용할 수 있습니다.
    - `max_new_tokens` 매개변수는 모델이 생성할 최대 토큰 개수를 설정합니다.
    - `return_full_text` 매개변수를 `False`로 지정하면 모델이 생성한 텍스트만 반환합니다. 기본값은 `True` 입니다.
    - `do_sample` 매개변수를 `True`로 지정하면 토큰 확률을 기반으로 다음 토큰을 선택합니다. 기본값은 `False` 입니다.
    - `temperature` 매개변수는 모델이 출력한 로짓의 분포를 조정하는 온도 파라미터입니다. 1.0보다 크면 토큰의 선택 가능성을 고르게 만들고 1.0보다 작으면 높은 확률의 토큰이 선택될 가능성이 더 커집니다. 기본값은 1.0입니다.
    - `top_k` 매개변수는 가장 큰 확률을 가진 토큰 k개를 다음 토큰의 후보로 설정합니다. 기본값은 50이며 이런 디코딩 전략을 `top-k` 샘플링이라고 합니다.
    - `top_p` 매개변수를 1.0보다 작게 설정하면 확률 크기 순으로 토큰을 나열했을 때 누적 확률이 지정한 값을 넘기지 않을 때까지 후보 토큰으로 설정합니다. 기본값은 1.0이며 이런 디코딩 전략을 `top_p` 샘플링이라고 합니다.

### openai

- **OpenAI** 클래스는 오픈 AI의 API호출을 위한 클라이언트 객체를 만듭니다./
    - `api_key` 매개변수에는 오픈 AI에서 발급받은 API 키를 지정합니다. 이 매개변수를 지정하지 않으면 `OPENAI_API_KEY` 환경 변수에 저장되어 값을 이용합니다.
- `OpenAI.chat.completion.create()` 메서드는 채팅 완성 API를 호출하고 GPT 모델의 응답을 반환합니다.
    - `model` 매개변수에 사용할 모델 아이디를 지정합니다.
    - `messages` 매개변수에 모델에게 전달할 대화 메세지를 입력합니다. 멀티모달 모델일 경우 텍스트 외에 이미지나 오디오 등을 전달할 수 있습니다. 
    - `temperature` 매개변수로 0\~2 사이의 온도 파라미터를 조정합니다. 기본값은 1입니다. 
    - `top_p` 매개변수로 `top-p` 샘플링을 설정합니다. 기본값은 1입니다. 
    - `max_completion_tokens` 매개변수로 모델이 생성할 최대 토큰 수를 지정합니다.