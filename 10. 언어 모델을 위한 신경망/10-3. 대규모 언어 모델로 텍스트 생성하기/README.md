# 대규모 언어 모델로 텍스트 생성하기

## 키워드 정리

- **EXAONE**은 LG AI 연구원에서 만든 트랜스포머 디코더 기반의 대규모 언어 모델입니다. 3.5버전은 한국어와 영어를 잘 이해하며 비교적 적은 모델 파라미터를 가진 모델 중에서 경쟁력이 있습니다. 최신 LLM에서 채택하는 여러 기술을 사용하고 있습니다. 그룹 쿼리 어텐션, 실루 활성화 함수, RMS 정규화, 로터리 위치 임베딩 등입니다. 
- **토큰 디코딩**은 대규모 언어 모델이 출력한 로짓을 바탕으로 다음 토큰을 선택하는 과정입니다. 가장 기본적인 방법은 로짓을 소프트맥스 함수에 통과시켜 확률로 바꾼 후 이 확률을 기반으로 다음 토큰을 선택합니다. 온도 파라미터를 높이면 비교적 낮은 확률의 토큰이 선택될 가능성을 높일 수 있습니다. 최상위 로짓의 일부 토큰을 선택하는 `top-k` 방식과 누적 확률의 임곗값으로 토큰을 선택하는 `top-p` 방식이 널리 사용됩니다.
- **GPT**는 오픈 AI에서 개발된 트랜스포머 디코더 기반의 대규모 언어 모델입니다. `GPT-2`는 공개 되어 있지만 `GPT-3` 부터는 클로즈드 소스 정책을 유지하고 있습니다. `GPT-3.5`를 기반으로 하는 `ChatGPT`는 인공지능 분야에 큰 영향을 미쳤습니다. 최신 `GPT-4o` 모델은 다양한 작업에서 뛰어난 성능을 내는 모델 중 하나입니다. `ChatGPT` 웹 인터페이스 또는 파이썬 같은 프로그래밍 언어를 위해 제공되는 API를 통해 이런 모델을 사용할 수 있습니다. 

### transformers

- **AutoTokenizer**는 허깅페이스에서 제공하는 사전 훈련된 LLM 모델의 토크나이저를 직접 로드하기 위한 클래스입니다. `from_pretrained()` 클래스 메서드에 허깅페이스 모델 경로를 전달하여 불러올 수 있습니다. 비슷하게 트랜스포머 디코더 기반의 LLM 모델을 불러오려면 `AutoModelForCausalLM` 클래스를 사용합니다. 
- 파이프라인 객체를 호출할 때 다음과 같은 매개변수를 사용할 수 있습니다.
    - `max_new_tokens` 매개변수는 모델이 생성할 최대 토큰 개수를 설정합니다.
    - `return_full_text` 매개변수를 `False`로 지정하면 모델이 생성한 텍스트만 반환합니다. 기본값은 `True` 입니다.
    - `do_sample` 매개변수를 `True`로 지정하면 토큰 확률을 기반으로 다음 토큰을 선택합니다. 기본값은 `False` 입니다.
    - `temperature` 매개변수는 모델이 출력한 로짓의 분포를 조정하는 온도 파라미터입니다. 1.0보다 크면 토큰의 선택 가능성을 고르게 만들고 1.0보다 작으면 높은 확률의 토큰이 선택될 가능성이 더 커집니다. 기본값은 1.0입니다.
    - `top_k` 매개변수는 가장 큰 확률을 가진 토큰 k개를 다음 토큰의 후보로 설정합니다. 기본값은 50이며 이런 디코딩 전략을 `top-k` 샘플링이라고 합니다.
    - `top_p` 매개변수를 1.0보다 작게 설정하면 확률 크기 순으로 토큰을 나열했을 때 누적 확률이 지정한 값을 넘기지 않을 때까지 후보 토큰으로 설정합니다. 기본값은 1.0이며 이런 디코딩 전략을 `top_p` 샘플링이라고 합니다.

### openai

- **OpenAI** 클래스는 오픈 AI의 API호출을 위한 클라이언트 객체를 만듭니다./
    - `api_key` 매개변수에는 오픈 AI에서 발급받은 API 키를 지정합니다. 이 매개변수를 지정하지 않으면 `OPENAI_API_KEY` 환경 변수에 저장되어 값을 이용합니다.
- `OpenAI.chat.completion.create()` 메서드는 채팅 완성 API를 호출하고 GPT 모델의 응답을 반환합니다.
    - `model` 매개변수에 사용할 모델 아이디를 지정합니다.
    - `messages` 매개변수에 모델에게 전달할 대화 메세지를 입력합니다. 멀티모달 모델일 경우 텍스트 외에 이미지나 오디오 등을 전달할 수 있습니다. 
    - `temperature` 매개변수로 0\~2 사이의 온도 파라미터를 조정합니다. 기본값은 1입니다. 
    - `top_p` 매개변수로 `top-p` 샘플링을 설정합니다. 기본값은 1입니다. 
    - `max_completion_tokens` 매개변수로 모델이 생성할 최대 토큰 수를 지정합니다.

## 디코더 기반의 대규모 언어 모델

- 앞에서 보았듯이 `ChatGPT`의 등장 이후 디코더 기반의 대규모 언어 모델(LLM)이 큰 인기를 얻고 있습니다. 디코더 기반 LLM은 텍스트 생성 능력이 특히 뛰어나기 때문에 종종 생성 언어 모델 또는 생성 언어 AI라고도 불립니다. 이러한 모델은 **오픈 소스**<sup>open source</sup> **모델**과 **클로즈드 소스**<sup>closed source</sup> **모델**로 나뉩니다.
- 대표적인 오픈 소스 모델은 다음과 같습니다.
  - 메타의 Llama : https://www.llama.com/
  - 구글의 Gemma : https://ai.google.dev/gemma
  - 마이크로소프트의 Phi : https://azure.microsoft.com/en-us/products/phi/
  - 알리바바의 Qwen : https://qwenlm.github.io/

- 사실 오픈 소스 LLM은 워낙 많아 모두 나열하기 힘듭니다. 특히 인기 있는 모델을 특정 데이터셋으로 다시 미세 튜닝한 변형 모델들도 많습니다. 하지만 메타나 구글과 같은 큰 규모의 회사에서 제공하는 언어 모델은 비교적 높은 성능과 지속적인 지원을 기대할 수 있습니다. 아마도 많은 경우에 여기서 소개하는 모델들이 좋은 출발접이 될 것입니다. 
- 대표적인 클로즈드 소스 모델은 다음과 같습니다.
    - 오픈 AI의 GPT-4 : https://chat.com
    - 엔트로픽(Anthropic)의 Claude : https://claude.ai/
    - 구글의 Gemini : https://gemini.google.com/ 
- 이런 클로즈드 소스 모델들은 모두 웹 인터페이스를 제공하므로, 브라우저에서 다른 사람과 채팅하듯이 모델에게 질문을 하거나 다양한 작업을 요청할 수 있습니다. 클로즈드 소스 LLM은 API 방식도 지원하기 때문에, 이를 활용하면 쉽게 연동하여 자동으로 댓글을 달 수 있습니다.
- 본격적으로 디코더 기반의 모델을 살펴보기 전에, 먼저 가장 높은 성능을 내는 모델을 찾는 방법을 알아보겠습니다. 

## LLM 리더보드
- 대규모 언어 모델의 성능을 비교하는 서비스가 많이 있습니다. 그중에서도 **오픈 LLM 리더보드**<sup>Open LLM leaderboard</sup>와 **LMSYS 챗봇 아레나 리더보드**<sup>LMSYS Chatbot Arena Leaderboard</sup>가 가장 널리 알려져 있습니다.
- 오픈 LLM 리더보드는 허깅페이스에서 제공하는 서비스로, 허깅페이스에 등록된 오픈 소스 LLM의 성능을 비교합니다. 오픈 소스 LLM 리더보드 사이트(https://bit.ly/4gylmPz)에 접속하면 다음과 같은 화면을 확인할 수 있습니다. 

![스크린샷 2025-04-19 오후 10 51 45](https://github.com/user-attachments/assets/ab6e23c3-f68e-48c8-9be2-eae5341a4f38)


- 이 리더보드를 잘 활용하면 특정 작업에 적합한 최신 모델을 쉽게 찾을 수 있습니다. 먼저 화면 아래에 나타난 순위를 살펴보죠. 이 글을 작성하는 시점에는 `calm-3.2-instruct-78b`가 1등을 차지하고 있군요. 모델을 클릭해서 상세 정보를 확인해 보면, 사실 이 모델은 `Qwen 72B` 모델을 미세 튜닝한 버전이라는 점도 알 수 있습니다. 모델의 순위가 어떤 기준으로 매겨졌는지 이해하면 적절한 모델을 선택하는 데 도움이 됩니다. 이 리더보드의 구성 요소를 하나씩 살펴보겠습니다.
- 먼저 목록의 왼쪽의 Type 열에 나타난 아이콘은 모델의 종류를 보여줍니다. 각 아이콘에 대한 설명은 다음과 같습니다.


![스크린샷 2025-04-19 오후 10 51 54](https://github.com/user-attachments/assets/f4a867cb-1df9-47b1-9f47-e53e02d67050)

