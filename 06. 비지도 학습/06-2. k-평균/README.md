# k-평균

## 키워드 정리

- **k-평균**
  - 처음에 랜덤하게 클러스터의 중심을 정하고 클러스터를 만듭니다. 그 다음 클러스터의 중심을 이동하고 다시 클러스터를 만드는 식으로 반복해서 최적의 클러스터를 구성하는 알고리즘입니다.
- **클러스터 중심**
  - k-평균 알고리즘이 만든 클러스터에 속한 샘플의 특성 평균값니다.
  - 센트로이드(centroid)라고도 부릅니다. 가장 가까운 클러스터 중심을 샘플의 또 다른 특성으로 사용하거나 새로운 새믈에 대한 예측으로 활용할 수 있습니다.
- **엘보우 방법**
  - 최적의 클러스터 개수를 정하는 방법 중 하나입니다.
  - 이너셔는 클러스터 중심과 샘플 사이 거리의 제곱 합입니다. 클러스터 개수에 따라 이니셔 감소가 꺾이는 지점이 적절한 클러스터 개수 k가 될 수 있습니다.
  - 이 그래프의 모양을 따서 엘보우 방법이라고 부릅니다.

## 핵심 패키지와 함수

### scikit-learn

- **KMeans**
  - k-평균 알고리즘 클래스입니다.
  - `n_clusters` 에는 클러스터 개수를 지정합니다. 기본값은 8입니다.
  - 처음에는 랜덤하게 센트로이드를 초기화하기 때문에 여러 번 반복하여 이너셔를 기준으로 가장 좋은 결과를 선택합니다. `n_init`는 이 반복 횟수를 지정합니다. 기본값은 10이었으나 사이킷런 버전 1.4에서는 `auto`로 변경될 예정입니다.
  - `max_iter`는 k-평균 알고리즘의 한 번 실행에서 최적의 센트로이드를 찾기 위해 반복할 수 있는 최대 횟수입니다. 기본값은 200입니다.


## 비지도 학습

- 앞서 사과, 파인애플, 바나나에 있는 각 픽셀의 평균값을 구해서 가장 가까운 사진을 골랐습니다. 이 경우에는 사과, 파인애플, 바나나 사진임을 미리 알고 있었기 때문에 각 과일의 평균을 구할 수 있었습니다. 하지만 진짜 비지도 학습에서는 사진에 어떤 과일이 들어 있는지 알지 못합니다.
- 이러 경우 **k-평균**(k-means) 군집 알고리즘을 사용하면 평균값을 자동으로 찾아줍니다.
- 이 평균값이 클러스터의 중심에 위치하기 때문에 **클러스터 중심**(cluster center) 또는 **센트로이드**(centroid)라고 부릅니다.

## k-평균 알고리즘 소개

k-평균 알고리즘의 작동 방식은 다음과 같습니다.

- 무작위로 k개의 클러스터 중심을 정합니다.
- 각 샘플에서 가장 가까운 클러스터 중심을 찾아 해당 클러스터의 샘플로 지정합니다.
- 클러스터에 속한 샘플의 평균값으로 클러스터 중심을 변경합니다.
- 클러스터 중심에 변화가 없을 때까지 2번 돌아가 반복합니다, 

![스크린샷 2024-11-10 오후 3 11 29](https://github.com/user-attachments/assets/95a9a157-dbd6-4a60-91cc-bf50b7189ff9)

- 먼저 3개의 클러스터 중심(빨간 점)을 랜덤하게 지정합니다(1). 그리고 클러스터 중심에서 가장 가까운 샘플을 하나의 클러스터로 묶습니다. 왼쪽 위부터 시계 방향으로 바나나 2개와 사과 1개 클러스터, 바나나 1개와 파인애플 2개 클러스터, 사과 2개와 파인애플 1개 클러스터가 만들어졌습니다. 클러스터에는 순서나 번호는 의미가 없습니다.
- 그 다음 클러스터의 중심을 다시 계산하여 이동시킵니다. 맨 아래 클러스터는 사과 쪽으로 중심이 조금 더 이동하고 왼쪽 위의 클러스터는 바나나 쪽으로 중심이 더 이동하는 식입니다.
- 그 다음 클러스터의 중심을 다시 계산하여 이동시킵니다. 맨 아래 클러스터는 사과 쪽으로 중심이 조금 더 이동하고 클러스터는 바나나 쪽으로 중심이 더 이동하는 식입니다. 
- 클러스터 중심을 다시 계산한 다음 가장 가까운 샘플을 다시 클러스터로 묶습니다(2). 이제 3개의 클러스터에는 바나나와 파인애플, 사과가 3개씩 올바르게 묶여 있습니다. 다시 한번 클러스터의 중심을 계산합니다. 그 다음 빨간 점을 클러스터의 가운데 부분으로 이동시킵니다.
- 이동된 클러스터의 중심에서 다시 한번 가장 가까운 샘플을 클러스터로 묶습니다(3). 중심에서 가장 가까운 샘플은 이전 클러스터(2)와 동일 합니다. 따라서 만들어진 클러스터에 변동이 없으므로 k-평균 알고리즘을 종료합니다.
- k-평균 알고리즘은 처음에는 랜덤하게 클러스터의 중심을 선택하고 점차 가장 가까운 샘플의 중심으로 이동하는 비교적 간단한 알고리즘입니다. 


## KMeans 클래스

- 사이킷런으로 k-평균 모델을 직접 만들 수 있습니다. 

```python
!wget https://bit.ly/fruits_300_data -O fruits_300.npy
```

- wget 명령으로 데이터를 다운로드 합니다.

```python
import numpy as np

fruits = np.load('fruits_300.npy')
fruits_2d = fruits.reshape(-1, 100*100)
```

- 넘파이 `np.load()` 함수를 사용해 npy 파일을 읽어 넘파이 배열을 준비합니다. k-평균 모델을 훈련하기 위해 (샘플 개수, 너비, 높이) 크기의 3차원 배열을 (샘플 개수, 너비 X 높이) 크기를 가진 2차원 배열로 변경합니다.

```python
from sklearn.cluster import KMeans

km = KMeans(n_clusters=3, random_state=42)
km.fit(fruits_2d)
```

- 사이킷런의 k-평균 알고리즘은 `sklearn.cluster` 모듈 아래 **KMeans** 클래스에 구현되어 있습니다. 
- 이 클래스에서 설정할 매개변수는 클러스터 개수를 지정하는 `n_cluster` 입니다. 여기에서는 클러스터 개수를 3으로 지정하겠습니다.
- 이 클래스를 사용하는 방법도 다른 클래스들과 비슷합니다. 다만 비지도 학습이므로 `fit()` 메서드에서 타깃 데이터를 사용하지 않습니다. 

```python
print(km.labels_)
```

- 군집된 결과는 **KMeans** 클래스 객체의 `labels_` 속성에 저장됩니다. **labels_** 배열의 길이는 샘플 개수와 같습니다. 
- 이 배열은 각 샘플이 어떤 레이블에 해당되는지 나타냅니다. `n_clusters=3` 으로 지정했기 때문에 `labels_` 배열의 값은 0, 1, 2 중 하나입니다.

```
[2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 0 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1]
```

- 레이블값 0, 1, 2와 레이블 순서에는 어떤 의미도 없습니다. 실제 레이블 0, 1, 2가 어떤 과일 사진을 주로 모았는지 알아보려면 직접 이미지를 출력하는 것이 최선입니다. 그 전에 레이블 0, 1, 2로 모은 샘플의 개수를 확인하겠습니다.

```python
print(np.unique(km.labels_, return_counts=True))
```

```
(array([0, 1, 2], dtype=int32), array([112,  98,  90]))
```

- 첫 번째 클러스터(레이블 0)가 111개의 샘플을 모았고, 두 번째 클러스터(레이블 1)가 98개의 샘플을 모았습니다.
- 세 번째 클러스터(레이블 2)는 91개의 샘플을 모았습니다. 그럼 각 클러스터가 어떤 이미지를 나타냈는지 그림으로 출력하기 위해 유틸리티 함수 `draw_fruits()` 를 만들어 봅니다.

```python
import matplotlib.pyplot as plt

def draw_fruits(arr, ratio=1):
    n = len(arr)    # n은 샘플 개수입니다
    # 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다.
    rows = int(np.ceil(n/10))
    # 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다.
    cols = n if rows < 2 else 10
    fig, axs = plt.subplots(rows, cols,
                            figsize=(cols*ratio, rows*ratio), squeeze=False)
    for i in range(rows):
        for j in range(cols):
            if i*10 + j < n:    # n 개까지만 그립니다.
                axs[i, j].imshow(arr[i*10 + j], cmap='gray_r')
            axs[i, j].axis('off')
    plt.show()
```

- `draw_fruits()` 함수는 (샘플 개수, 너비, 높이)의 3차원 배열을 입력받아 가로로 10개씩 이미지를 출력합니다. 샘플 개수에 따라 행과 열의 개수를 계산하고 `figsize`를 지정합니다. `figsize`는 `ratio` 매개변수에 비례하여 커집니다. `ratio`의 기본값은 1입니다.

- 그 다음 2중 for 반복문을 사용하여 먼저 첫 번째 행을 따라 이미지를 그립니다. 그리고 두 번째 행의 이미지를 그리는 식으로 계속됩니다.

```python
draw_fruits(fruits[km.labels_==0])
```

- 이 함수를 사용해 레이블이 0인 과일 사진을 모두 그려 보겠습니다. `km.labels_ == 0`과 같이 쓰면 `km.labels_` 배열에서 값이 0인 위치는 True,그 외에는 모두 False가 됩니다. 넘파이는 이런 불리언 배열을 사용해 원소를 선택할 수 있습니다. 이를 **불리언 인덱싱**이라고 합니다. 
- 넘파이 배열에 불리언 인덱싱을 적용하면 True인 위치의 원소만 모두 추출합니다.  



```python
draw_fruits(fruits[km.labels_==1])
```

```python
draw_fruits(fruits[km.labels_==2])
```

## 클러스터 중심

```python
draw_fruits(km.cluster_centers_.reshape(-1, 100, 100), ratio=3)
```

```python
print(km.transform(fruits_2d[100:101]))
```

```
[[3400.24197319 8837.37750892 5279.33763699]]
```

```python
print(km.predict(fruits_2d[100:101]))
```

```
[0]
```

```python
draw_fruits(fruits[100:101])
```

```python
print(km.n_iter_)
```

```
4
```

## 최적의 k 찾기

```python
inertia = []
for k in range(2, 7):
    km = KMeans(n_clusters=k, n_init='auto', random_state=42)
    km.fit(fruits_2d)
    inertia.append(km.inertia_)

plt.plot(range(2, 7), inertia)
plt.xlabel('k')
plt.ylabel('inertia')
plt.show()
```
